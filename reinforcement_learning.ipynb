{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "This Jupyter notebook acts as supporting material for **Chapter 21 Reinforcement Learning** of the book* Artificial Intelligence: A Modern Approach*. This notebook makes use of the implementations in `rl.py` module. We also make use of implementation of MDPs in the `mdp.py` module to test our agents. It might be helpful if you have already gone through the Jupyter notebook dealing with Markov decision process. Let us import everything from the `rl` module. It might be helpful to view the source of some of our implementations. Please refer to the Introductory Jupyter notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reinforcement_learning4e import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENTS\n",
    "\n",
    "* Overview\n",
    "* Passive Reinforcement Learning\n",
    "    - Direct Utility Estimation\n",
    "    - Adaptive Dynamic Programming\n",
    "    - Temporal-Difference Agent\n",
    "* Active Reinforcement Learning\n",
    "    - Q learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## OVERVIEW\n",
    "\n",
    "Before we start playing with the actual implementations let us review a couple of things about RL.\n",
    "\n",
    "1. Reinforcement Learning is concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. \n",
    "\n",
    "2. Reinforcement learning differs from standard supervised learning in that correct input/output pairs are never presented, nor sub-optimal actions explicitly corrected. Further, there is a focus on on-line performance, which involves finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).\n",
    "\n",
    "-- Source: [Wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning)\n",
    "\n",
    "In summary we have a sequence of state action transitions with rewards associated with some states. Our goal is to find the optimal policy $\\pi$ which tells us what action to take in each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASSIVE REINFORCEMENT LEARNING\n",
    "\n",
    "In passive Reinforcement Learning the agent follows a fixed policy $\\pi$. Passive learning attempts to evaluate the given policy $pi$ - without any knowledge of the Reward function $R(s)$ and the Transition model $P(s'\\ |\\ s, a)$.\n",
    "\n",
    "This is usually done by some method of **utility estimation**. The agent attempts to directly learn the utility of each state that would result from following the policy. Note that at each step, it has to *perceive* the reward and the state - it has no global knowledge of these. Thus, if a certain the entire set of actions offers a very low probability of attaining some state $s_+$ - the agent may never perceive the reward $R(s_+)$.\n",
    "\n",
    "Consider a situation where an agent is given a policy to follow. Thus, at any point it knows only its current state and current reward, and the action it must take next. This action may lead it to more than one state, with different probabilities.\n",
    "\n",
    "For a series of actions given by $\\pi$, the estimated utility $U$:\n",
    "$$U^{\\pi}(s) = E(\\sum_{t=0}^\\inf \\gamma^t R^t(s')$$)\n",
    "Or the expected value of summed discounted rewards until termination.\n",
    "\n",
    "Based on this concept, we discuss three methods of estimating utility:\n",
    "\n",
    "1. **Direct Utility Estimation (DUE)**\n",
    " \n",
    " The first, most naive method of estimating utility comes from the simplest interpretation of the above definition. We construct an agent that follows the policy until it reaches the terminal state. At each step, it logs its current state, reward. Once it reaches the terminal state, it can estimate the utility for each state for *that* iteration, by simply summing the discounted rewards from that state to the terminal one.\n",
    "\n",
    " It can now run this 'simulation' $n$ times, and calculate the average utility of each state. If a state occurs more than once in a simulation, both its utility values are counted separately.\n",
    " \n",
    " Note that this method may be prohibitively slow for very large statespaces. Besides, **it pays no attention to the transition probability $P(s'\\ |\\ s, a)$.** It misses out on information that it is capable of collecting (say, by recording the number of times an action from one state led to another state). The next method addresses this issue.\n",
    " \n",
    "2. **Adaptive Dynamic Programming (ADP)**\n",
    " \n",
    " This method makes use of knowledge of the past state $s$, the action $a$, and the new perceived state $s'$ to estimate the transition probability $P(s'\\ |\\ s,a)$. It does this by the simple counting of new states resulting from previous states and actions.<br> \n",
    " The program runs through the policy a number of times, keeping track of:\n",
    "    - each occurrence of state $s$ and the policy-recommended action $a$ in $N_{sa}$\n",
    "    - each occurrence of $s'$ resulting from $a$ on $s$ in $N_{s'|sa}$.\n",
    "     \n",
    " It can thus estimate $P(s'\\ |\\ s,a)$ as $N_{s'|sa}/N_{sa}$, which in the limit of infinite trials, will converge to the true value.<br>\n",
    " Using the transition probabilities thus estimated, it can apply `POLICY-EVALUATION` to estimate the utilities $U(s)$ using properties of convergence of the Bellman functions.\n",
    "\n",
    "3. **Temporal-difference learning (TD)**\n",
    " \n",
    " Instead of explicitly building the transition model $P$, the temporal-difference model makes use of the expected closeness between the utilities of two consecutive states $s$ and $s'$.\n",
    " For the transition $s$ to $s'$, the update is written as:\n",
    "$$U^{\\pi}(s) \\leftarrow U^{\\pi}(s) + \\alpha \\left( R(s) + \\gamma U^{\\pi}(s') - U^{\\pi}(s) \\right)$$\n",
    " This model implicitly incorporates the transition probabilities by being weighed for each state by the number of times it is achieved from the current state. Thus, over a number of iterations, it converges similarly to the Bellman equations.\n",
    " The advantage of the TD learning model is its relatively simple computation at each step, rather than having to keep track of various counts.\n",
    " For $n_s$ states and $n_a$ actions the ADP model would have $n_s \\times n_a$ numbers $N_{sa}$ and $n_s^2 \\times n_a$ numbers $N_{s'|sa}$ to keep track of. The TD model must only keep track of a utility $U(s)$ for each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrating Passive agents\n",
    "\n",
    "Passive agents are implemented in `rl.py` as various `Agent-Class`es.\n",
    "\n",
    "To demonstrate these agents, we make use of the `GridMDP` object from the `MDP` module. `sequential_decision_environment` is similar to that used for the `MDP` notebook but has discounting with $\\gamma = 0.9$.\n",
    "\n",
    "The `Agent-Program` can be obtained by creating an instance of the relevant `Agent-Class`. The `__call__` method allows the `Agent-Class` to be called as a function. The class needs to be instantiated with a policy ($\\pi$) and an `MDP` whose utility of states will be estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp4e import sequential_decision_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sequential_decision_environment` is a GridMDP object as shown below. The rewards are **+1** and **-1** in the terminal states, and **-0.04** in the rest. <img src=\"files/images/mdp.png\"> Now we define actions and a policy similar to **Fig 21.1** in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Directions\n",
    "north = (0, 1)\n",
    "south = (0,-1)\n",
    "west = (-1, 0)\n",
    "east = (1, 0)\n",
    "\n",
    "# policy = {\n",
    "#     (0, 2): east, (1, 2): east,  (2, 2): east,   (3, 2): None,\n",
    "#     (0, 1): north,               (2, 1): north,    (3, 1): None,\n",
    "#     (0, 0): north, (1, 0): west,                   (3, 0): north, \n",
    "# }\n",
    "\n",
    "policy = {\n",
    "    (0, 7): east,  (1, 7): east,  (2, 7): east,   (3, 7): east, (4, 7): east,  (5, 7): east,  (6, 7): east,   (7, 7): None,\n",
    "    (0, 6): north, (1, 6): north, (2, 6): north,  (3, 6): north, (4, 6): east,  (5, 6): east,  (6, 6): east,   (7, 6): north,\n",
    "    (0, 5): north, (1, 5): north,  (2, 5): west,   (3, 5): west, (4, 5): east,  (5, 5): north, (6, 5): east,    (7, 5): north,\n",
    "    (0, 4): north, (1, 4): north, (2, 4): north,  (3, 4): north,                                               (7, 4): north,\n",
    "    (0, 3): north, (1, 3): north, (2, 3): north,  (3, 3): north, (4, 3): east,  (5, 3): east,  (6, 3): east,   (7, 3): north,\n",
    "    (0, 2): north, (1, 2): north, (2, 2): north,   (3, 2): west, (4, 2): east,  (5, 2): east,  (6, 2): east,   (7, 2): north,\n",
    "    (0, 1): east, (1, 1): east, (2, 1): north,   (3, 1): east,  (4, 1): east,  (5, 1): east,  (6, 1): east,   (7, 1): north,\n",
    "    (0, 0): east, (1, 0): east,  (2, 0): east,   (3, 0): east, (4, 0): east,  (5, 0): east,  (6, 0): east,   (7, 0): north\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Direction Utility Estimation Agent\n",
    "\n",
    "The `PassiveDEUAgent` class in the `rl` module implements the Agent Program described in **Fig 21.2** of the AIMA Book. `PassiveDEUAgent` sums over rewards to find the estimated utility for each state. It thus requires the running of a number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %psource PassiveDUEAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUEagent = PassiveDUEAgent(policy, sequential_decision_environment)\n",
    "# for i in range(1000):\n",
    "#     run_single_trial(DUEagent, sequential_decision_environment)\n",
    "#     DUEagent.estimate_U()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated utilities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join([str(k)+':'+str(v) for k, v in DUEagent.U.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Dynamic Programming Agent\n",
    "\n",
    "The `PassiveADPAgent` class in the `rl` module implements the Agent Program described in **Fig 21.2** of the AIMA Book. `PassiveADPAgent` uses state transition and occurrence counts to estimate $P$, and then $U$. Go through the source below to understand the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %psource PassiveADPAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a `PassiveADPAgent` below with the `GridMDP` shown and train it over 200 iterations. The `rl` module has a simple implementation to simulate iterations. The function is called **run_single_trial**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ADPagent = PassiveADPAgent(policy, sequential_decision_environment)\n",
    "# for i in range(200):\n",
    "#     run_single_trial(ADPagent, sequential_decision_environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated utilities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('\\n'.join([str(k)+':'+str(v) for k, v in ADPagent.U.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Temporal Difference Agent\n",
    "\n",
    "`PassiveTDAgent` uses temporal differences to learn utility estimates. We learn the difference between the states and backup the values to previous states.  Let us look into the source before we see some usage examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mclass\u001b[0m \u001b[0mPassiveTDAgent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"\n",
      "    [Figure 21.4]\n",
      "    The abstract class for a Passive (non-learning) agent that uses\n",
      "    temporal differences to learn utility estimates. Override update_state\n",
      "    method to convert percept to state and reward. The mdp being provided\n",
      "    should be an instance of a subclass of the MDP Class.\n",
      "\n",
      "    import sys\n",
      "    from mdp import sequential_decision_environment\n",
      "    north = (0, 1)\n",
      "    south = (0,-1)\n",
      "    west = (-1, 0)\n",
      "    east = (1, 0)\n",
      "    policy = {(0, 2): east, (1, 2): east, (2, 2): east, (3, 2): None, (0, 1): north, (2, 1): north,\n",
      "              (3, 1): None, (0, 0): north, (1, 0): west, (2, 0): west, (3, 0): west,}\n",
      "    agent = PassiveTDAgent(policy, sequential_decision_environment, alpha=lambda n: 60./(59+n))\n",
      "    for i in range(200):\n",
      "        run_single_trial(agent,sequential_decision_environment)\n",
      "\n",
      "    agent.U[(0, 0)] > 0.2\n",
      "    True\n",
      "    agent.U[(0, 1)] > 0.2\n",
      "    True\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# udacity video\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mNs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0ms1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mterminals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"To be overridden in most cases. The default case\n",
      "        assumes the percept to be of type (state, reward).\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%psource PassiveTDAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In creating the `TDAgent`, we use the **same learning rate** $\\alpha$ as given in the footnote of the book on **page 837**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDagent = PassiveTDAgent(policy, sequential_decision_environment, alpha = lambda n: 60./(59+n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run **200 trials** for the agent to estimate Utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    run_single_trial(TDagent,sequential_decision_environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated utilities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0):-3.776592437760811\n",
      "(3, 4):-0.6890015671086918\n",
      "(4, 3):0.0\n",
      "(3, 1):-10.068560673753828\n",
      "(3, 7):5.643518354335809\n",
      "(4, 6):5.62898359431928\n",
      "(5, 1):-4.995111509706312\n",
      "(5, 7):6.90561090728745\n",
      "(0, 2):-10.233678226140626\n",
      "(0, 5):2.7048516562445117\n",
      "(2, 2):-6.482755883920653\n",
      "(1, 0):-2.507578633025894\n",
      "(1, 6):3.907602158119431\n",
      "(2, 5):-8.717203915950991\n",
      "(1, 3):-0.23989053677920769\n",
      "(7, 4):-7.785761829981916\n",
      "(6, 2):-6.6383890209673355\n",
      "(7, 1):-5.490350688478396\n",
      "(7, 7):10\n",
      "(6, 5):4.6485269544012935\n",
      "(4, 2):-14.561886905021675\n",
      "(3, 0):-3.270863330347803\n",
      "(4, 5):-0.07600000000000001\n",
      "(3, 3):-7.931495145682831\n",
      "(5, 0):-3.362726053381414\n",
      "(5, 6):6.1193208196557904\n",
      "(3, 6):4.105103895130135\n",
      "(5, 3):-4.413776172731517\n",
      "(0, 1):-5.335648504086942\n",
      "(0, 7):3.3149640477954776\n",
      "(2, 4):-8.69415643979331\n",
      "(1, 2):-2.848379659659668\n",
      "(0, 4):0.42355802522341723\n",
      "(2, 1):-4.303102259421593\n",
      "(2, 7):4.375490792322571\n",
      "(1, 5):2.269735591191042\n",
      "(6, 1):-4.732843897474174\n",
      "(7, 0):-4.6485910749908355\n",
      "(7, 3):-8.782823504319902\n",
      "(6, 7):8.959944621731747\n",
      "(7, 6):8.753706246773886\n",
      "(3, 2):-0.9499434311562966\n",
      "(4, 1):-5.078689749513487\n",
      "(4, 7):6.8610151147869765\n",
      "(3, 5):-9.092861092920089\n",
      "(5, 2):-15.168512261858266\n",
      "(5, 5):2.236638059192582\n",
      "(0, 0):-2.6701841150190364\n",
      "(1, 1):-3.9245869803040945\n",
      "(0, 3):-1.323188395058835\n",
      "(2, 0):-2.8717637679200467\n",
      "(1, 4):1.3031417471065065\n",
      "(0, 6):2.344565994955226\n",
      "(2, 3):-7.007447500138662\n",
      "(1, 7):4.422880775596586\n",
      "(2, 6):2.1923333647039924\n",
      "(7, 2):-7.332481949665257\n",
      "(6, 0):-3.864878432201324\n",
      "(6, 6):7.628562039466932\n",
      "(7, 5):5.844409090997742\n",
      "(6, 3):-6.781101867000468\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([str(k)+':'+str(v) for k, v in TDagent.U.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with value iteration method\n",
    "\n",
    "We can also compare the utility estimates learned by our agent to those obtained via **value iteration**.\n",
    "\n",
    "**Note that value iteration has a priori knowledge of the transition table $P$, the rewards $R$, and all the states $s$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp4e import value_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values calculated by value iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0):0.9592510249999024\n",
      "(3, 4):2.6349467338527726\n",
      "(4, 3):1.715247637279368\n",
      "(3, 1):1.3829435900868137\n",
      "(3, 7):5.494284372144781\n",
      "(4, 6):5.71406783878458\n",
      "(5, 1):-0.38535416824539664\n",
      "(5, 7):7.4193318608091126\n",
      "(0, 2):-9.820133506405137\n",
      "(0, 5):2.398260610591679\n",
      "(2, 2):1.4386419043106127\n",
      "(1, 0):0.8419079520284465\n",
      "(1, 6):3.328140145359859\n",
      "(2, 5):-7.287409284790501\n",
      "(1, 3):1.35543386148279\n",
      "(7, 4):-6.615198954254923\n",
      "(6, 2):-0.9589122799027445\n",
      "(7, 1):0.3059652579224845\n",
      "(7, 7):10\n",
      "(6, 5):6.466073568419178\n",
      "(4, 2):0.46900699946848556\n",
      "(3, 0):1.1324204929929418\n",
      "(4, 5):5.047704330346447\n",
      "(3, 3):2.1648142058688427\n",
      "(5, 0):0.6768851565987255\n",
      "(5, 6):6.561871328703023\n",
      "(3, 6):4.866467118500668\n",
      "(5, 3):-0.7071236278313471\n",
      "(0, 1):-0.5590418580100129\n",
      "(0, 7):3.3553307744592225\n",
      "(2, 4):0.61089314654446\n",
      "(1, 2):0.24096024787873435\n",
      "(0, 4):2.0156579695723336\n",
      "(2, 1):1.2034360152593828\n",
      "(2, 7):4.605136138329179\n",
      "(1, 5):1.1737813827816246\n",
      "(6, 1):0.33027444592634125\n",
      "(7, 0):0.4010485406473782\n",
      "(7, 3):-1.0864248815234758\n",
      "(6, 7):8.612532741324099\n",
      "(7, 6):8.612532741324099\n",
      "(3, 2):1.6903529459331528\n",
      "(4, 1):1.0842575889164445\n",
      "(4, 7):6.391412137661514\n",
      "(3, 5):3.3094743157471176\n",
      "(5, 2):-9.760644243703277\n",
      "(5, 5):5.721034493234349\n",
      "(0, 0):0.5668618672320155\n",
      "(1, 1):0.9239257064850616\n",
      "(0, 3):0.6299584956901095\n",
      "(2, 0):1.004156957954898\n",
      "(1, 4):1.6389026141474854\n",
      "(0, 6):2.9399678678642167\n",
      "(2, 3):1.7031228274044974\n",
      "(1, 7):3.9288248666526107\n",
      "(2, 6):3.053212668940834\n",
      "(7, 2):0.10319973833239648\n",
      "(6, 0):0.5242419673584922\n",
      "(6, 6):7.526719940055513\n",
      "(7, 5):6.354912302099722\n",
      "(6, 3):-0.6982965935983698\n"
     ]
    }
   ],
   "source": [
    "U_values = value_iteration(sequential_decision_environment)\n",
    "print('\\n'.join([str(k)+':'+str(v) for k, v in U_values.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of utility estimates over iterations\n",
    "\n",
    "We can explore how these estimates vary with time by using plots similar to **Fig 21.5a**. We will first enable matplotlib using the inline backend. We also define a function to collect the values of utilities at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph_utility_estimates(agent_program, mdp, no_of_iterations, states_to_graph):\n",
    "    graphs = {state:[] for state in states_to_graph}\n",
    "    for iteration in range(1,no_of_iterations+1):\n",
    "        run_single_trial(agent_program, mdp)\n",
    "        for state in states_to_graph:\n",
    "            graphs[state].append((iteration, agent_program.U[state]))\n",
    "    for state, value in graphs.items():\n",
    "        state_x, state_y = zip(*value)\n",
    "        plt.plot(state_x, state_y, label=str(state))\n",
    "    #plt.ylim([0,1.2])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of state $(2,2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = PassiveTDAgent(policy, sequential_decision_environment, alpha=lambda n: 60./(59+n))\n",
    "graph_utility_estimates(agent, sequential_decision_environment, 500, [(2,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to plot multiple states on the same plot. As expected, the utility of the finite state $(3,2)$ stays constant and is equal to $R((3,2)) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_utility_estimates(agent, sequential_decision_environment, 500, [(2,2), (3,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ACTIVE REINFORCEMENT LEARNING\n",
    "\n",
    "Unlike Passive Reinforcement Learning in Active Reinforcement Learning we are not bound by a policy pi and we need to select our actions. In other words the agent needs to learn an optimal policy. The fundamental tradeoff the agent needs to face is that of exploration vs. exploitation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLearning Agent\n",
    "\n",
    "The QLearningAgent class in the rl module implements the Agent Program described in **Fig 21.8** of the AIMA Book. In Q-Learning the agent learns an action-value function Q which gives the utility of taking a given action in a particular state. Q-Learning does not required a transition model and hence is a model free method. Let us look into the source before we see some usage examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mclass\u001b[0m \u001b[0mQLearningAgent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"\n",
      "    [Figure 21.8]\n",
      "    An exploratory Q-learning agent. It avoids having to learn the transition\n",
      "    model because the Q-value of a state can be related directly to those of\n",
      "    its neighbors.\n",
      "\n",
      "    import sys\n",
      "    from mdp import sequential_decision_environment\n",
      "    north = (0, 1)\n",
      "    south = (0,-1)\n",
      "    west = (-1, 0)\n",
      "    east = (1, 0)\n",
      "    policy = {(0, 2): east, (1, 2): east, (2, 2): east, (3, 2): None, (0, 1): north, (2, 1): north,\n",
      "              (3, 1): None, (0, 0): north, (1, 0): west, (2, 0): west, (3, 0): west,}\n",
      "    q_agent = QLearningAgent(sequential_decision_environment, Ne=5, Rplus=2, alpha=lambda n: 60./(59+n))\n",
      "    for i in range(200):\n",
      "        run_single_trial(q_agent,sequential_decision_environment)\n",
      "\n",
      "    q_agent.Q[((0, 1), (0, 1))] >= -0.5\n",
      "    True\n",
      "    q_agent.Q[((1, 0), (0, -1))] <= 0.5\n",
      "    True\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRplus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_act\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactlist\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNe\u001b[0m  \u001b[1;31m# iteration limit in exploration function\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRplus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRplus\u001b[0m  \u001b[1;31m# large value to assign before iteration limit\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNsa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# udacity video\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Exploration function. Returns fixed Rplus until\n",
      "        agent has visited state, action a Ne number of times.\n",
      "        Same as ADP agent in book.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRplus\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mactions_in_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Return actions possible in given state.\n",
      "        Useful for max and argmax.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_act\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNsa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNsa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mactions_in_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions_in_state\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mterminals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mNsa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNsa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                           \u001b[1;32mfor\u001b[0m \u001b[0ma1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions_in_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mterminals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions_in_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNsa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"To be overridden in most cases. The default case\n",
      "        assumes the percept to be of type (state, reward).\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%psource QLearningAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Agent Program can be obtained by creating the instance of the class by passing the appropriate parameters. Because of the __ call __ method the object that is created behaves like a callable and returns an appropriate action as most Agent Programs do. To instantiate the object we need a mdp similar to the PassiveTDAgent.\n",
    "\n",
    " Let us use the same GridMDP object we used above. **Figure 17.1 (sequential_decision_environment)** is similar to **Figure 21.1** but has some discounting as **gamma = 0.9**. The class also implements an exploration function **f** which returns fixed **Rplus** until agent has visited state, action **Ne** number of times. This is the same as the one defined on page **842** of the book. The method **actions_in_state** returns actions possible in given state. It is useful when applying max and argmax operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create our object now. We also use the **same alpha** as given in the footnote of the book on **page 837**. We use **Rplus = 2** and **Ne = 5** as defined on page 843. **Fig 21.7**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_agent = QLearningAgent(sequential_decision_environment, Ne=5, Rplus=2, \n",
    "                         alpha=lambda n: 60./(59+n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to try out the q_agent we make use of the **run_single_trial** function in rl.py (which was also used above). Let us use **200** iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    run_single_trial(q_agent,sequential_decision_environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see the Q Values. The keys are state-action pairs. Where different actions correspond according to:\n",
    "\n",
    "north = (0, 1)\n",
    "south = (0,-1)\n",
    "west = (-1, 0)\n",
    "east = (1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {((0, 0), (1, 0)): -0.6043094380743917,\n",
       "             ((0, 0), (0, 1)): -0.8557407632661569,\n",
       "             ((0, 0), (-1, 0)): -0.8631304148766692,\n",
       "             ((0, 0), (0, -1)): -0.3893120164677773,\n",
       "             ((0, 1), (1, 0)): -1.5547617871675163,\n",
       "             ((0, 1), (0, 1)): -8.848090546659508,\n",
       "             ((0, 1), (-1, 0)): -1.8307692307692307,\n",
       "             ((0, 1), (0, -1)): -1.8630385322151075,\n",
       "             ((0, 2), (1, 0)): -11.034017686945276,\n",
       "             ((0, 2), (0, 1)): -18.307692307692307,\n",
       "             ((0, 2), (-1, 0)): -18.529738416751073,\n",
       "             ((0, 2), (0, -1)): -11.13269213406477,\n",
       "             ((1, 2), (1, 0)): -1.2405981128298447,\n",
       "             ((1, 2), (0, 1)): -8.338886193603093,\n",
       "             ((1, 2), (-1, 0)): -9.119773649820072,\n",
       "             ((1, 2), (0, -1)): -1.361362329016103,\n",
       "             ((2, 2), (1, 0)): -0.2992430980174962,\n",
       "             ((2, 2), (0, 1)): -0.5342857335681652,\n",
       "             ((2, 2), (-1, 0)): -0.4837998727767375,\n",
       "             ((2, 2), (0, -1)): -0.5204954215409693,\n",
       "             ((3, 2), (1, 0)): -0.8725494505494508,\n",
       "             ((3, 2), (0, 1)): -0.8367852875365741,\n",
       "             ((3, 2), (-1, 0)): -0.2833928624457611,\n",
       "             ((3, 2), (0, -1)): -0.8481327503602458,\n",
       "             ((4, 2), (1, 0)): -10.00129566836369,\n",
       "             ((4, 2), (0, 1)): -9.75363538910948,\n",
       "             ((4, 2), (-1, 0)): -1.2568072846145857,\n",
       "             ((4, 2), (0, -1)): -1.6703609484669686,\n",
       "             ((5, 2), (1, 0)): -10.920478555588328,\n",
       "             ((5, 2), (0, 1)): -10.896651382858284,\n",
       "             ((5, 2), (-1, 0)): -10.895673076923078,\n",
       "             ((5, 2), (0, -1)): -11.047815317249029,\n",
       "             ((6, 2), (1, 0)): -1.4029043488906805,\n",
       "             ((6, 2), (0, 1)): -10.027527218934912,\n",
       "             ((6, 2), (-1, 0)): -9.35219821500174,\n",
       "             ((6, 2), (0, -1)): -1.7237722718788269,\n",
       "             ((6, 3), (1, 0)): -0.8707692307692309,\n",
       "             ((6, 3), (0, 1)): -0.8912236752830048,\n",
       "             ((6, 3), (-1, 0)): -1.3826049081204803,\n",
       "             ((6, 3), (0, -1)): -1.3160235732009933,\n",
       "             ((7, 3), (1, 0)): -1.8307692307692307,\n",
       "             ((7, 3), (0, 1)): -1.5357142857142865,\n",
       "             ((7, 3), (-1, 0)): -1.6788268525930288,\n",
       "             ((7, 3), (0, -1)): -1.0950724530295193,\n",
       "             ((7, 4), (1, 0)): -25.734265734265733,\n",
       "             ((7, 4), (0, 1)): -23.62525467022678,\n",
       "             ((7, 4), (-1, 0)): -25.734265734265733,\n",
       "             ((7, 4), (0, -1)): -11.515318700406294,\n",
       "             ((7, 5), (1, 0)): -1.0,\n",
       "             ((7, 5), (0, 1)): -0.06688844059885568,\n",
       "             ((7, 5), (-1, 0)): -7.781884449255795,\n",
       "             ((7, 5), (0, -1)): -8.893765653101022,\n",
       "             ((7, 6), (1, 0)): -0.04,\n",
       "             ((7, 6), (0, 1)): 3.048141084634261,\n",
       "             ((7, 6), (-1, 0)): 0.7532864354644668,\n",
       "             ((7, 6), (0, -1)): 0.43656128759391,\n",
       "             ((7, 7), None): 3.616460069878868,\n",
       "             ((1, 0), (1, 0)): -0.5060317383459007,\n",
       "             ((1, 0), (0, 1)): -0.38822643335633433,\n",
       "             ((1, 0), (-1, 0)): -0.3863388099584348,\n",
       "             ((1, 0), (0, -1)): -0.37829295570596966,\n",
       "             ((2, 0), (1, 0)): -0.35405569310054086,\n",
       "             ((2, 0), (0, 1)): -0.3426386175261728,\n",
       "             ((2, 0), (-1, 0)): -0.3527745476579888,\n",
       "             ((2, 0), (0, -1)): -0.3564619540879313,\n",
       "             ((3, 0), (1, 0)): -0.36627046237712113,\n",
       "             ((3, 0), (0, 1)): -0.3620694103139416,\n",
       "             ((3, 0), (-1, 0)): -0.34189641361858436,\n",
       "             ((3, 0), (0, -1)): -0.3676006787932374,\n",
       "             ((4, 0), (1, 0)): -0.39912048072535816,\n",
       "             ((4, 0), (0, 1)): -0.4262585416419467,\n",
       "             ((4, 0), (-1, 0)): -0.7000315376121783,\n",
       "             ((4, 0), (0, -1)): -0.36910537879360106,\n",
       "             ((5, 0), (1, 0)): -0.8180681493680412,\n",
       "             ((5, 0), (0, 1)): -0.8750960448858387,\n",
       "             ((5, 0), (-1, 0)): -0.8863421658986176,\n",
       "             ((5, 0), (0, -1)): -0.38454168040558784,\n",
       "             ((6, 0), (1, 0)): -0.3870397215341211,\n",
       "             ((6, 0), (0, 1)): -0.6993398964344018,\n",
       "             ((6, 0), (-1, 0)): -0.38749849270324743,\n",
       "             ((6, 0), (0, -1)): -0.38669400521548675,\n",
       "             ((7, 0), (1, 0)): -0.3927804892388623,\n",
       "             ((7, 0), (0, 1)): -0.38925034778353845,\n",
       "             ((7, 0), (-1, 0)): -0.40170659024389177,\n",
       "             ((7, 0), (0, -1)): -0.3925182347863341,\n",
       "             ((7, 1), (1, 0)): -0.4414454311334786,\n",
       "             ((7, 1), (0, 1)): -0.6054278594578772,\n",
       "             ((7, 1), (-1, 0)): -0.49892316565741784,\n",
       "             ((7, 1), (0, -1)): -0.39136733400476253,\n",
       "             ((7, 2), (1, 0)): -0.8612027972027972,\n",
       "             ((7, 2), (0, 1)): -0.8707692307692309,\n",
       "             ((7, 2), (-1, 0)): -0.9376596450424577,\n",
       "             ((7, 2), (0, -1)): -0.3985792901106415,\n",
       "             ((2, 1), (1, 0)): -0.3318498057310356,\n",
       "             ((2, 1), (0, 1)): -0.3117891544751231,\n",
       "             ((2, 1), (-1, 0)): -0.5235220997300727,\n",
       "             ((2, 1), (0, -1)): -0.3297827856705608,\n",
       "             ((3, 1), (1, 0)): -0.35815576107138974,\n",
       "             ((3, 1), (0, 1)): -0.4168473880417287,\n",
       "             ((3, 1), (-1, 0)): -0.31697099712850013,\n",
       "             ((3, 1), (0, -1)): -0.33776383708148,\n",
       "             ((4, 1), (1, 0)): -0.8707692307692309,\n",
       "             ((4, 1), (0, 1)): -0.8709752747252748,\n",
       "             ((4, 1), (-1, 0)): -0.3635109520684816,\n",
       "             ((4, 1), (0, -1)): -0.8583597909292722,\n",
       "             ((5, 1), (1, 0)): -9.4375,\n",
       "             ((5, 1), (0, 1)): -10.04782511864685,\n",
       "             ((5, 1), (-1, 0)): -1.4884747906325229,\n",
       "             ((5, 1), (0, -1)): -1.318152644548736,\n",
       "             ((6, 1), (1, 0)): -0.992175508358609,\n",
       "             ((6, 1), (0, 1)): -0.9399135944700462,\n",
       "             ((6, 1), (-1, 0)): -0.9374067402103478,\n",
       "             ((6, 1), (0, -1)): -0.4346879595379432,\n",
       "             ((5, 3), (1, 0)): -1.0327272727272727,\n",
       "             ((5, 3), (0, 1)): -1.5243454825701461,\n",
       "             ((5, 3), (-1, 0)): -1.8307692307692307,\n",
       "             ((5, 3), (0, -1)): -9.987723815704928,\n",
       "             ((4, 3), (1, 0)): -0.8707692307692309,\n",
       "             ((4, 3), (0, 1)): -0.6963550937541377,\n",
       "             ((4, 3), (-1, 0)): -0.09268663077162388,\n",
       "             ((4, 3), (0, -1)): -0.8707692307692309,\n",
       "             ((3, 3), (1, 0)): -0.1520149136681565,\n",
       "             ((3, 3), (0, 1)): -0.08222045315344063,\n",
       "             ((3, 3), (-1, 0)): -0.15956710803534394,\n",
       "             ((3, 3), (0, -1)): -0.20217104803708608,\n",
       "             ((3, 4), (1, 0)): -0.052097499209530856,\n",
       "             ((3, 4), (0, 1)): -0.5974345364888339,\n",
       "             ((3, 4), (-1, 0)): -0.5625185229344741,\n",
       "             ((3, 4), (0, -1)): -0.6779959500296369,\n",
       "             ((3, 5), (1, 0)): 0.5763002783396477,\n",
       "             ((3, 5), (0, 1)): -0.6136776693868973,\n",
       "             ((3, 5), (-1, 0)): -7.138284207444475,\n",
       "             ((3, 5), (0, -1)): -0.702728391313171,\n",
       "             ((4, 5), (1, 0)): 1.3365073888509695,\n",
       "             ((4, 5), (0, 1)): 1.8586300192095886,\n",
       "             ((4, 5), (-1, 0)): 0.20994047851007536,\n",
       "             ((4, 5), (0, -1)): 0.737880668077823,\n",
       "             ((5, 5), (1, 0)): 1.3773601258481678,\n",
       "             ((5, 5), (0, 1)): 2.140703900852418,\n",
       "             ((5, 5), (-1, 0)): 1.3402970568928543,\n",
       "             ((5, 5), (0, -1)): 1.2237750263160867,\n",
       "             ((6, 5), (1, 0)): 1.4481782229810058,\n",
       "             ((6, 5), (0, 1)): 0.7946258587008662,\n",
       "             ((6, 5), (-1, 0)): 1.2905723383818488,\n",
       "             ((6, 5), (0, -1)): 1.2559456827120108,\n",
       "             ((1, 1), (1, 0)): -0.7983338327366041,\n",
       "             ((1, 1), (0, 1)): -0.823173289709866,\n",
       "             ((1, 1), (-1, 0)): -0.9443991752978043,\n",
       "             ((1, 1), (0, -1)): -0.3746155388205316,\n",
       "             ((2, 4), (1, 0)): -1.046852411597865,\n",
       "             ((2, 4), (0, 1)): -7.04762543849698,\n",
       "             ((2, 4), (-1, 0)): -0.9837467536690262,\n",
       "             ((2, 4), (0, -1)): -1.1376082570424846,\n",
       "             ((2, 3), (1, 0)): -0.8077720742506861,\n",
       "             ((2, 3), (0, 1)): -0.7813926709621619,\n",
       "             ((2, 3), (-1, 0)): -0.721926383487844,\n",
       "             ((2, 3), (0, -1)): -0.206393143703375,\n",
       "             ((6, 6), (1, 0)): 0.793331108510791,\n",
       "             ((6, 6), (0, 1)): 1.8169505130312698,\n",
       "             ((6, 6), (-1, 0)): 1.8696347818787946,\n",
       "             ((6, 6), (0, -1)): 1.56977446767168,\n",
       "             ((3, 6), (1, 0)): 0.4361897407772363,\n",
       "             ((3, 6), (0, 1)): 2.459932966546873,\n",
       "             ((3, 6), (-1, 0)): 0.0,\n",
       "             ((3, 6), (0, -1)): 0.0,\n",
       "             ((3, 7), (1, 0)): 2.2342188886702177,\n",
       "             ((3, 7), (0, 1)): 0.0,\n",
       "             ((3, 7), (-1, 0)): 0.0,\n",
       "             ((3, 7), (0, -1)): 0.0,\n",
       "             ((4, 6), (1, 0)): 1.8746341733890373,\n",
       "             ((4, 6), (0, 1)): 2.0791609538887985,\n",
       "             ((4, 6), (-1, 0)): 0.0,\n",
       "             ((4, 6), (0, -1)): 0.0,\n",
       "             ((6, 7), (1, 0)): 3.265223649933976,\n",
       "             ((6, 7), (0, 1)): 0.0,\n",
       "             ((6, 7), (-1, 0)): 0.0,\n",
       "             ((6, 7), (0, -1)): 0.0,\n",
       "             ((1, 3), (1, 0)): -0.8587985187301664,\n",
       "             ((1, 3), (0, 1)): 0.1020842675350703,\n",
       "             ((1, 3), (-1, 0)): -0.9084044115161554,\n",
       "             ((1, 3), (0, -1)): -1.0908065403392,\n",
       "             ((0, 3), (1, 0)): -0.8515441247548758,\n",
       "             ((0, 3), (0, 1)): -1.7471747645380333,\n",
       "             ((0, 3), (-1, 0)): -1.8307536411706988,\n",
       "             ((0, 3), (0, -1)): -10.42147391454263,\n",
       "             ((2, 5), (1, 0)): -8.333938882767718,\n",
       "             ((2, 5), (0, 1)): -10.0,\n",
       "             ((2, 5), (-1, 0)): -7.279549138931549,\n",
       "             ((2, 5), (0, -1)): -9.423554085092452,\n",
       "             ((5, 6), (1, 0)): 1.846447239696202,\n",
       "             ((5, 6), (0, 1)): 2.4956017106315183,\n",
       "             ((5, 6), (-1, 0)): 0.0,\n",
       "             ((5, 6), (0, -1)): 0.0,\n",
       "             ((1, 4), (1, 0)): -0.7561184455147063,\n",
       "             ((1, 4), (0, 1)): -0.3218249878913473,\n",
       "             ((1, 4), (-1, 0)): 0.01130898612275319,\n",
       "             ((1, 4), (0, -1)): -0.5582991248725433,\n",
       "             ((4, 7), (1, 0)): 2.4878897254607653,\n",
       "             ((4, 7), (0, 1)): 0.0,\n",
       "             ((4, 7), (-1, 0)): 0.0,\n",
       "             ((4, 7), (0, -1)): 0.0,\n",
       "             ((5, 7), (1, 0)): 2.9100931395986467,\n",
       "             ((5, 7), (0, 1)): 0.0,\n",
       "             ((5, 7), (-1, 0)): 0.0,\n",
       "             ((5, 7), (0, -1)): 0.0,\n",
       "             ((2, 6), (1, 0)): -0.9765956211084814,\n",
       "             ((2, 6), (0, 1)): 1.3191216098939655,\n",
       "             ((2, 6), (-1, 0)): 0.14986017972465215,\n",
       "             ((2, 6), (0, -1)): 0.0,\n",
       "             ((2, 7), (1, 0)): 2.018161170792698,\n",
       "             ((2, 7), (0, 1)): 0.0,\n",
       "             ((2, 7), (-1, 0)): 0.0,\n",
       "             ((2, 7), (0, -1)): 0.0,\n",
       "             ((0, 4), (1, 0)): -0.7263176893466661,\n",
       "             ((0, 4), (0, 1)): 1.3680630877762658,\n",
       "             ((0, 4), (-1, 0)): 0.017727117893054388,\n",
       "             ((0, 4), (0, -1)): -0.7114813270658062,\n",
       "             ((1, 5), (1, 0)): -1.0,\n",
       "             ((1, 5), (0, 1)): 0.03405619026866513,\n",
       "             ((1, 5), (-1, 0)): 0.4210516175323785,\n",
       "             ((1, 5), (0, -1)): -0.44927500439640833,\n",
       "             ((1, 6), (1, 0)): 1.2776224219162802,\n",
       "             ((1, 6), (0, 1)): 2.0988701069728655,\n",
       "             ((1, 6), (-1, 0)): 0.0,\n",
       "             ((1, 6), (0, -1)): 0.0,\n",
       "             ((0, 5), (1, 0)): 0.13857612073659675,\n",
       "             ((0, 5), (0, 1)): 1.599929433075459,\n",
       "             ((0, 5), (-1, 0)): 0.2652938785846577,\n",
       "             ((0, 5), (0, -1)): 1.0340591037866664,\n",
       "             ((0, 6), (1, 0)): 0.14361342199907945,\n",
       "             ((0, 6), (0, 1)): 1.5405461690411155,\n",
       "             ((0, 6), (-1, 0)): 0.0,\n",
       "             ((0, 6), (0, -1)): 0.0,\n",
       "             ((1, 7), (1, 0)): 1.8651242041511007,\n",
       "             ((1, 7), (0, 1)): 1.8123232738381303,\n",
       "             ((1, 7), (-1, 0)): 0.0,\n",
       "             ((1, 7), (0, -1)): 0.0,\n",
       "             ((0, 7), (1, 0)): 1.6422219907111375,\n",
       "             ((0, 7), (0, 1)): 0.0,\n",
       "             ((0, 7), (-1, 0)): 0.0,\n",
       "             ((0, 7), (0, -1)): 0.0})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_agent.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Utility **U** of each state is related to **Q** by the following equation.\n",
    "\n",
    "**U (s) = max <sub>a</sub> Q(s, a)**\n",
    "\n",
    "Let us convert the Q Values above into U estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = defaultdict(lambda: -1000.) # Very Large Negative Value for Comparison see below.\n",
    "for state_action, value in q_agent.Q.items():\n",
    "    state, action = state_action\n",
    "    if U[state] < value:\n",
    "                U[state] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {(0, 0): -0.3893120164677773,\n",
       "             (0, 1): -1.5547617871675163,\n",
       "             (0, 2): -11.034017686945276,\n",
       "             (1, 2): -1.2405981128298447,\n",
       "             (2, 2): -0.2992430980174962,\n",
       "             (3, 2): -0.2833928624457611,\n",
       "             (4, 2): -1.2568072846145857,\n",
       "             (5, 2): -10.895673076923078,\n",
       "             (6, 2): -1.4029043488906805,\n",
       "             (6, 3): -0.8707692307692309,\n",
       "             (7, 3): -1.0950724530295193,\n",
       "             (7, 4): -11.515318700406294,\n",
       "             (7, 5): -0.06688844059885568,\n",
       "             (7, 6): 3.048141084634261,\n",
       "             (7, 7): 3.616460069878868,\n",
       "             (1, 0): -0.37829295570596966,\n",
       "             (2, 0): -0.3426386175261728,\n",
       "             (3, 0): -0.34189641361858436,\n",
       "             (4, 0): -0.36910537879360106,\n",
       "             (5, 0): -0.38454168040558784,\n",
       "             (6, 0): -0.38669400521548675,\n",
       "             (7, 0): -0.38925034778353845,\n",
       "             (7, 1): -0.39136733400476253,\n",
       "             (7, 2): -0.3985792901106415,\n",
       "             (2, 1): -0.3117891544751231,\n",
       "             (3, 1): -0.31697099712850013,\n",
       "             (4, 1): -0.3635109520684816,\n",
       "             (5, 1): -1.318152644548736,\n",
       "             (6, 1): -0.4346879595379432,\n",
       "             (5, 3): -1.0327272727272727,\n",
       "             (4, 3): -0.09268663077162388,\n",
       "             (3, 3): -0.08222045315344063,\n",
       "             (3, 4): -0.052097499209530856,\n",
       "             (3, 5): 0.5763002783396477,\n",
       "             (4, 5): 1.8586300192095886,\n",
       "             (5, 5): 2.140703900852418,\n",
       "             (6, 5): 1.4481782229810058,\n",
       "             (1, 1): -0.3746155388205316,\n",
       "             (2, 4): -0.9837467536690262,\n",
       "             (2, 3): -0.206393143703375,\n",
       "             (6, 6): 1.8696347818787946,\n",
       "             (3, 6): 2.459932966546873,\n",
       "             (3, 7): 2.2342188886702177,\n",
       "             (4, 6): 2.0791609538887985,\n",
       "             (6, 7): 3.265223649933976,\n",
       "             (1, 3): 0.1020842675350703,\n",
       "             (0, 3): -0.8515441247548758,\n",
       "             (2, 5): -7.279549138931549,\n",
       "             (5, 6): 2.4956017106315183,\n",
       "             (1, 4): 0.01130898612275319,\n",
       "             (4, 7): 2.4878897254607653,\n",
       "             (5, 7): 2.9100931395986467,\n",
       "             (2, 6): 1.3191216098939655,\n",
       "             (2, 7): 2.018161170792698,\n",
       "             (0, 4): 1.3680630877762658,\n",
       "             (1, 5): 0.4210516175323785,\n",
       "             (1, 6): 2.0988701069728655,\n",
       "             (0, 5): 1.599929433075459,\n",
       "             (0, 6): 1.5405461690411155,\n",
       "             (1, 7): 1.8651242041511007,\n",
       "             (0, 7): 1.6422219907111375})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us finally compare these estimates to value_iteration results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(4, 0): 0.9592510249999024, (3, 4): 2.6349467338527726, (4, 3): 1.715247637279368, (3, 1): 1.3829435900868137, (3, 7): 5.494284372144781, (4, 6): 5.71406783878458, (5, 1): -0.38535416824539664, (5, 7): 7.4193318608091126, (0, 2): -9.820133506405137, (0, 5): 2.398260610591679, (2, 2): 1.4386419043106127, (1, 0): 0.8419079520284465, (1, 6): 3.328140145359859, (2, 5): -7.287409284790501, (1, 3): 1.35543386148279, (7, 4): -6.615198954254923, (6, 2): -0.9589122799027445, (7, 1): 0.3059652579224845, (7, 7): 10, (6, 5): 6.466073568419178, (4, 2): 0.46900699946848556, (3, 0): 1.1324204929929418, (4, 5): 5.047704330346447, (3, 3): 2.1648142058688427, (5, 0): 0.6768851565987255, (5, 6): 6.561871328703023, (3, 6): 4.866467118500668, (5, 3): -0.7071236278313471, (0, 1): -0.5590418580100129, (0, 7): 3.3553307744592225, (2, 4): 0.61089314654446, (1, 2): 0.24096024787873435, (0, 4): 2.0156579695723336, (2, 1): 1.2034360152593828, (2, 7): 4.605136138329179, (1, 5): 1.1737813827816246, (6, 1): 0.33027444592634125, (7, 0): 0.4010485406473782, (7, 3): -1.0864248815234758, (6, 7): 8.612532741324099, (7, 6): 8.612532741324099, (3, 2): 1.6903529459331528, (4, 1): 1.0842575889164445, (4, 7): 6.391412137661514, (3, 5): 3.3094743157471176, (5, 2): -9.760644243703277, (5, 5): 5.721034493234349, (0, 0): 0.5668618672320155, (1, 1): 0.9239257064850616, (0, 3): 0.6299584956901095, (2, 0): 1.004156957954898, (1, 4): 1.6389026141474854, (0, 6): 2.9399678678642167, (2, 3): 1.7031228274044974, (1, 7): 3.9288248666526107, (2, 6): 3.053212668940834, (7, 2): 0.10319973833239648, (6, 0): 0.5242419673584922, (6, 6): 7.526719940055513, (7, 5): 6.354912302099722, (6, 3): -0.6982965935983698}\n"
     ]
    }
   ],
   "source": [
    "print(value_iteration(sequential_decision_environment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08ed8f9a424e71ecb4dc69db0334cf3f416d9ce53adb05348e5735c903720564"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
